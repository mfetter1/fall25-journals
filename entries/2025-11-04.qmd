---
title: "2025-11-04"
format:
  html: default
  pdf: default
params:
  course: "mc501"
  word_min: 450
  word_max: 500
  p1: 'Have you ever worked with a spreadsheet, dataset, or even a shared document that felt chaotic or disorganized? Describe the experience. What kinds of "messiness" did you encounter? Looking back, which data wrangling principles from this chapter would have helped clean it up?'
  p2: 'Imagine you''re analyzing survey data and discover that some responses are missing or strangely formatted. You realize you could remove them, impute values, or rewrite categories to make things "fit." What would guide your decision-making in that situation? How does data cleaning impact the honesty and transparency of research?'
  p3: 'The chapter argues that wrangling is not just technical work—it’s interpretive. Think about a time you had to make a judgment call while organizing information (e.g., editing a document, categorizing files, formatting content). How might similar interpretive choices show up in data wrangling? How does this shape the final story your data tells?'
---

## Choose **one** prompt to answer

> **Prompt B:** `r params$p2`

---

## Response

<!-- RESPONSE-START -->
Understanding why data are missing or inconsistent is the first step toward dealing with such a situation. Data may be missing for many reasons, such as participants skipping questions out of confusion, discomfort, or survey fatigue, or possibly even because of technical issues that prevented proper submission. In addition, responses that are strangely formatted suggest poor survey design, miscommunication of instructions, or respondent error. The identified cause can help to establish an appropriate solution. For example, if data loss is random-for example, perhaps a few participants accidentally skipped one question-statistical imputation methods (such as mean substitution or regression-based imputation) may be appropriate. However, if missingness is systematic-for example, if certain groups consistently skip a sensitive question-eliminating those responses could make the data biased. Knowing this, acknowledging one's limitation and conducting sensitivity analyses would in that case become the far better option ethically and transparently.
Clear, preestablished protocols should guide a researcher's decision-making as well. The research plan/codebook should detail, in advance, how missing or anomalous data are to be treated. This type of proactive planning reduces the potential to engage in subjective decisions that can inadvertently manipulate the outcome. For instance, "rewriting categories to make things fit" might seem like an innocuous way to simplify data, but doing so can distort the original meaning of responses unless it is done in a systematic fashion and with justification. Recoding should only take place when categories conceptually overlap or when collapsing them enhances interpretability without erasing meaningful distinctions. Each modification should be documented in such a way that others can later replicate or evaluate the process.
Data cleaning has direct effects on the honesty and transparency of research. Cleaning data is not just a technical but also an ethical step. Transparency implies that any type of changes to the raw data should be fully documented in the methodology section. Researchers should explain what decisions were made, why they were necessary, and how they might affect results. Concealment of the procedures for data cleaning could mislead readers about the reliability of the findings, or it could imply a degree of precision not actually present. Overcleaning data in order to make results appear neater or more statistically significant crosses into unethical territory; it violates the integrity of the dataset and may lead to incorrect conclusions.
Ultimately, cleaning should not alter but retain the truth reflected in the data. There is a fine balance between the need to create datasets that can actually be used and the responsibility of not violating the original integrity of participants' responses. Ethical cleaning is based on transparency, accountability, and respect for limitations in data. By documenting procedures, justifying decisions, and acknowledging uncertainties, researchers ensure their findings are trustworthy and reproducible, upholding principles of honest and transparent scientific inquiry.
<!-- RESPONSE-END -->

---

## Word Count & Range Check

```{r}
#| echo: false
#| message: false
#| warning: false
get_response_text <- function() {
  f <- knitr::current_input()
  if (is.null(f) || !file.exists(f)) return("")
  x <- readLines(f, warn = FALSE)
  # Find the lines that EXACTLY match the start/end markers
  s <- grep("^<!-- RESPONSE-START -->$", x)
  e <- grep("^<!-- RESPONSE-END -->$", x)
  if (length(s) != 1 || length(e) != 1 || e <= s) return("")
  paste(x[(s + 1L):(e - 1L)], collapse = "\n")
}
count_words <- function(txt) {
  # Remove code blocks and inline code before counting
  txt <- gsub("```[\\s\\S]*?```", " ", txt, perl = TRUE)
  txt <- gsub("`[^`]*`", " ", txt, perl = TRUE)
  # Keep letters, numbers, spaces, hyphens, and apostrophes
  txt <- gsub("[^\\p{L}\\p{N}\\s'-]", " ", txt, perl = TRUE)
  # Split by whitespace and count non-empty words
  words <- unlist(strsplit(txt, "\\s+", perl = TRUE))
  words <- words[nzchar(words)]
  length(words)
}
txt <- get_response_text()
n <- count_words(txt)
minw <- as.integer(params$word_min)
maxw <- as.integer(params$word_max)
in_range <- n >= minw && n <= maxw
cat(sprintf("**Word count:** %d  \n", n))
cat(sprintf("**Required range (%s):** %d–%d words  \n",
            toupper(params$course), minw, maxw))
cat(if (in_range) "**Status:** ✅ In range\n" else "**Status:** ❌ Out of range\n")
```
